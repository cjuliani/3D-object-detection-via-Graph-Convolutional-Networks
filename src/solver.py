from __future__ import absolute_importfrom __future__ import divisionfrom __future__ import print_functionimport osimport configimport randomimport copyimport numpy as npimport tensorflow as tffrom sampler import Samplerfrom src.utils.dataset import reload_data, squared_dist_npfrom src.utils.visualization import plot_point_cloudfrom src.utils.box import get_mean_iou_3d, get_3D_box_corners, get_element, get_boxes_2D, get_boxes_3Dfrom src.models.pyramid_gcn import PyramidGraphConvNetfrom src.models.models import VotingModule, FullyConnectedSeqfrom src.models.utils import average_aggregationfrom src.utils.dataset import squared_disttf.compat.v1.disable_eager_execution()class Solver(object):    """Modules used for building network and metrics, and training."""    def __init__(self):        self.current_folder = None        self.positive_box_corners = None        self.pred_angle_res_enc = None        self.loss_angle_cls = None        self.loss_mean_centroid = None        self.pred_centers = None        self.positive_xyz = None        self.pred_sizes = None        self.loss_sizes = None        self.loss_sem = None        self.loss_weights = None        self.xyz_factor = None        self.pred_sem = None        self.iou = None        self.sem_f1 = None        self.recall = None        self.precision = None        self.sem_gt_ratio = None        self.cent_acc = None        self.metric_names = None        self.metrics = None        self.sem_acc = None        self.pointset_xyz = None        self.proposals = None        self.pointset_norm_xyz = None        self.segmentation = None        self.pointset_feat = None        self.seeds_feat = None        self.votes_xyz = None        self.votes_xyz = None        self.gt_obj_ids = None        self.seeds_xyz = None        self.votes = None        self.gt_sem = None        self.pred_delta = None        self.pred_centers_xyz = None        self.seeds = None        self.loss_center = None        self.positive_centers = None        self.delta_pred = None        self.delta_gt = None        self.pred_box_corners = None        self.loss = None        self.pred_angle_res = None        self.validation_writer = None        self.train_writer = None        self.merged = None        self.change_lr = None        self.pred_angle_cls = None        self.loss_angle_res = None        self.loss_corners = None        # Get of create summary folders.        self.summary_dir = os.path.join(config.SUMMARY_DIR, config.MODEL_DIR)        if not os.path.exists(self.summary_dir):            os.makedirs(self.summary_dir)        self.train_summary_dir = os.path.join(self.summary_dir, 'train')        if not os.path.exists(self.train_summary_dir):            os.makedirs(self.train_summary_dir)        self.val_summary_dir = os.path.join(self.summary_dir, 'validation')        if not os.path.exists(self.val_summary_dir):            os.makedirs(self.val_summary_dir)        # Get checkpoint folder, create it if not existing        if not os.path.exists(config.CHECKPOINT_DIR + config.MODEL_DIR):            os.makedirs(config.CHECKPOINT_DIR + config.MODEL_DIR)        # Get data folder        self.sampler = Sampler()        _, _ = self.generate_batch(training_phase='training')  # 1st call to initialize sampler        # Define placeholders.        self.placeholders = {            'point_set': tf.compat.v1.placeholder(tf.float32, [None, None, None, 3], 'point_set'),            'batch_xyz': tf.compat.v1.placeholder(tf.float32, [None, None, 3], name='batch_xyz'),            'batch_keys': tf.compat.v1.placeholder(tf.int32, [None, None, 1], name='batch_keys'),            'training': tf.compat.v1.placeholder(tf.bool, shape=[], name='training'),            'learning_rate': tf.compat.v1.placeholder(tf.float32, name='learning_rate'),            'object_ids': tf.compat.v1.placeholder(tf.int32, [None], 'object_ids'),            'box_sizes': tf.compat.v1.placeholder(tf.float64, [None, 3], 'box_sizes'),            'obj_ids_counts': tf.compat.v1.placeholder(tf.int64, [None], 'obj_ids_counts'),            'centers': tf.compat.v1.placeholder(tf.float64, [None, 3], 'centers'),            'box_angles_cls': tf.compat.v1.placeholder(tf.int32, [None], 'box_angles_cls'),            'box_angles_res': tf.compat.v1.placeholder(tf.float64, [None], 'box_angles_res'),            'box_vertices': tf.compat.v1.placeholder(tf.float64, [None, 8, 3], 'box_vertices')        }        self.build_network()        # Define saver to save variables to checkpoint files.        self.saver = tf.compat.v1.train.Saver()    def build_network(self):        """Define network sequence with associate loss and metric        estimations."""        self.pointset_feat, self.pointset_xyz, self.xyz_factor = average_aggregation(self.placeholders['point_set'])        self.pointset_norm_xyz = self.pointset_xyz / self.xyz_factor  # (B, P, 3)        features = tf.concat([self.pointset_norm_xyz, self.pointset_feat], axis=-1)        # Get model output.        backbone = PyramidGraphConvNet(            xyz=self.pointset_xyz,            features=features,            istraining=self.placeholders['training'])        self.seeds = backbone()        self.seeds_xyz = self.seeds[..., -3:]  # (B, P, 3)        self.seeds_feat = self.seeds[..., :-3]        # Estimate segmentation.        seg_net = FullyConnectedSeq(config.SEG_UNITS, bias=config.BIAS, batchnorm=config.BATCH_NORM)        self.segmentation = seg_net(tf.nn.relu(self.seeds), training=self.placeholders['training'])  # (B, P, 2)        # Get ground truth segmentation.        indicator = tf.cast(tf.math.greater(self.placeholders['object_ids'], 0), tf.int32)  # (P,)        indicator = tf.tile(tf.expand_dims(indicator, axis=0), multiples=[tf.shape(features)[0], 1])  # (B, P)        self.gt_sem = tf.gather_nd(indicator, self.placeholders['batch_keys'], batch_dims=1)  # (B, P)        # Estimate votes (object centers).        voting = VotingModule(config.VOTING_UNITS, bias=config.BIAS, batchnorm=config.BATCH_NORM)        self.votes = voting(tf.nn.relu(tf.expand_dims(self.seeds[0], axis=0)), training=self.placeholders['training'])        self.votes_xyz = self.votes[..., -3:]  # (P, 3)        # Define center predictions.        self.pred_delta = self.votes_xyz - (self.pointset_norm_xyz[0] * self.seeds_xyz[0])        self.pred_centers_xyz = self.pointset_xyz[0] + self.pred_delta        # Define proposals.        proposal_gen = FullyConnectedSeq(config.PROPOSAL_UNITS, bias=config.BIAS, batchnorm=config.BATCH_NORM)        self.proposals = proposal_gen(tf.nn.relu(self.votes), training=self.placeholders['training'])        # Get ground truth object ids.        self.gt_obj_ids = tf.expand_dims(            tf.gather_nd(self.placeholders['object_ids'],                         self.placeholders['batch_keys'][0]), axis=-1)  # (P, 1)        # Estimate losses and metrics.        self.define_losses()        self.build_metrics()    def mean_average_precision(self, sess, feed_dict, cluster_radius, assign_radius):        # Get boxes from predictions, given indices of ground truth semantics        # if the point scene contains 2 ground truth boxes, there should be        # 2 clusters of points (of centers) distinct from each others in space.        # Therefore, we need to (1) collect one box per cluster representing with        # the best IoU. Then, we relate these boxes to ground truth boxes by        # checking spatially if their respective centers are close to those of        # the 2 ground truth boxes (i.e. situated within a ball-region radius.        box_corners = sess.run(self.pred_box_corners, feed_dict=feed_dict)        centers = sess.run(self.pred_centers, feed_dict=feed_dict)        gt_box_corners = sess.run(self.positive_box_corners, feed_dict=feed_dict)        gt_box_centers = sess.run(self.positive_centers, feed_dict=feed_dict)        # Calculate distance matrix and cluster by distance radius.        dist_matrix = squared_dist(self.pred_centers, self.pred_centers)        mask = tf.cast(tf.less_equal(dist_matrix, cluster_radius), tf.int32)        mask = sess.run(mask, feed_dict=feed_dict)  # (None, None)        def calculate_ious(gt_boxes, pred_boxes):            return tf.py_function(get_mean_iou_3d, inp=[pred_boxes, gt_boxes, False], Tout=tf.float32)        def get_best_boxes_indices(masks, feed_dict_, gt_boxes, boxes):            # Retrieve individual box per existing object given predictions.            boxes_idx, to_skip = [], []            for row in masks:                if 1 in row:                    indices = np.where(row > 0)[0]                    if any(i in to_skip for i in indices):                        continue                    to_skip += list(indices)                    # Limit the number of indices per cluster because                    # the calculation of ious may be much longer otherwise.                    indices = np.random.choice(indices, size=config.IOU_NUMBER, replace=False)                    tmp_boxes = tf.gather_nd(boxes, tf.expand_dims(indices, axis=1))                    tmp_gt_boxes = tf.gather_nd(gt_boxes, tf.expand_dims(indices, axis=1))                    ious = sess.run(calculate_ious(tmp_gt_boxes, tmp_boxes), feed_dict=feed_dict_)  # (None, 1)                    # Collect best iou among the clusters' points (i.e. where masks row = 1).                    best_iou_idx = np.argmax(ious)                    boxes_idx.append(indices[best_iou_idx])  # collect best box index in current row            return np.array(boxes_idx)        # Get objects' individual centers from predictions and        # ground truth.        boxes_idxs = get_best_boxes_indices(mask, feed_dict, gt_box_corners, box_corners)        # If no predicted boxes, no TP.        if len(boxes_idxs) != 0:            # Collect centers for distance matrix.            p_centers = centers[boxes_idxs]            # Get distance matrix and calculate TP, FP, FN given how close            # gt/pred centers are (i.e. if they target same object)            dist_matrix = sess.run(                squared_dist(gt_box_centers[boxes_idxs], p_centers))  # e.g. (4,2) = 4 gt obj, 2 predicted obj            mask = np.less_equal(dist_matrix, assign_radius).astype(np.int32)            gt_TP = dist_matrix.shape[0]  # number of ground truth objects            TP = np.sum(np.max(mask, axis=1))  # hence, TP = 4 - 2 = 2 if the 2 pred objects target 2 gt objects            FN = np.abs(gt_TP - TP)  # number of pred objects - TP            # hypothesis: 1 gt_center not associated to 2 pred_center,            # but 1 pred_center possibly associated to 2 gt_centers (e.g. in crowded scenes)            # calculate how many times gt_center with 2 pred_centers            FP = np.sum(np.greater_equal(np.sum(mask, axis=1), 2).astype(np.int8))        else:            TP = 0.            FN = dist_matrix.shape[0]  # number of pred objects - TP            FP = 0.  # number of ground truth objects - TP        precision = TP / (TP + FP + 1e-10)        recall = TP / (TP + FN + 1e-10)        return precision, recall    def build_metrics(self):        """Define metrics to be displayed while training."""        epsilon = tf.constant(value=1e-10)        # Normal metrics (non differentiable)        self.pred_sem = tf.cast(tf.argmax(tf.nn.softmax(self.segmentation, axis=-1), axis=-1), tf.int32)  # (B, P)        TP = tf.compat.v1.count_nonzero(self.pred_sem * self.gt_sem, dtype=tf.float32, axis=-1)  # (B,)        FP = tf.compat.v1.count_nonzero(self.pred_sem * (1 - self.gt_sem), dtype=tf.float32, axis=-1)        FN = tf.compat.v1.count_nonzero((1 - self.pred_sem) * self.gt_sem, dtype=tf.float32, axis=-1)        # divide_no_NAN in case no TP exists in sample.        rec = tf.math.divide_no_nan(TP, (TP + FN))  # (B,)        prec = tf.math.divide_no_nan(TP, (TP + FP))        self.recall, self.precision = rec[0], prec[0]        self.sem_f1 = (2 * prec * rec / (prec + rec + epsilon))[0]        sem_acc = tf.reduce_mean(tf.cast(tf.equal(self.pred_sem, self.gt_sem), tf.float32), axis=1)  # (B,)        self.sem_acc = sem_acc[0]        # Intersection over union (IoU).        rand_indices = tf.random.shuffle(tf.range(tf.shape(self.positive_box_corners)[0]))[:config.IOU_NUMBER]        with tf.control_dependencies([rand_indices]):            # what you specify in the argument to control_dependencies is ensured to be evaluated            # before anything you define in the with block.            pred_box_corners = tf.where(tf.compat.v1.is_nan(self.pred_box_corners),                                        tf.zeros_like(self.pred_box_corners),                                        self.pred_box_corners)            self.iou = tf.py_function(get_mean_iou_3d,                                      inp=[                                          tf.gather_nd(self.positive_box_corners, tf.expand_dims(rand_indices, axis=1)),                                          tf.gather_nd(pred_box_corners, tf.expand_dims(rand_indices, axis=1))],                                      Tout=tf.float32)        # center accuracy        # self.cent_acc = tf.reduce_mean(tf.norm(self.pred_centers - self.positive_centers, axis=1))        self.cent_acc = tf.reduce_mean(tf.norm(self.pred_centers - self.positive_centers, axis=1))        # semantics ground truth        self.sem_gt_ratio = tf.reduce_mean(tf.reduce_mean(tf.cast(self.gt_sem, tf.float32), axis=-1))        # define summaries        self.metrics = [self.loss, self.loss_sem, self.loss_center, self.loss_angle_cls,                        self.loss_angle_res, self.loss_sizes, self.loss_corners, self.iou,                        self.sem_f1, self.sem_acc, self.recall, self.precision,                        self.loss_mean_centroid]        self.metric_names = ['loss', 'loss_sem', 'loss_center', 'loss_angle_cls', 'loss_angle_res',                             'loss_sizes', 'loss_corners', 'iou', 'sem_f1', 'sem_acc', 'sem_rec',                             'sem_prec', 'centroid']        for tensor, name in zip(self.metrics, self.metric_names):            tf.compat.v1.summary.scalar('summary/' + name, tensor)        tf.compat.v1.summary.histogram('summary/' + 'segmentation', self.segmentation)        tf.compat.v1.summary.histogram('summary/' + 'pred_centers', self.pred_centers)        tf.compat.v1.summary.histogram('summary/' + 'delta_gt', self.delta_gt)        tf.compat.v1.summary.histogram('summary/' + 'delta_pred', self.delta_pred)    def weighted_binary_crossentropy(self, y_true, y_pred, w0, w1, gamma=0):        """Returns cross entropy loss weighted for segmentation task."""        gt_sem_enc = tf.one_hot(self.gt_sem, axis=-1, depth=2)  # (B, P, 2)        if gamma > 0:            # Focal loss.            gt_sem_enc = gt_sem_enc * tf.pow(1 - y_pred, gamma)        bce = tf.losses.binary_crossentropy(y_pred=y_pred, y_true=gt_sem_enc)        # Apply the weights        weight_vector = y_true * w1 + (1. - y_true) * w0        weighted_bce = weight_vector * bce        return tf.reduce_mean(weighted_bce)    def select_object_of_interest_from_batch(self, obj_n):        """Select a random object to learn the box properties from.        WARNING: it seems important to learn from one box at a time per batch because        if the scene is cluttered and contains (many) small/big objects close to each others,        it becomes difficult for the network to learn. Below, we thus select the object id that is        the most represented in batch. First, check how many points related to known objects in batch.        Then, collect the object idx whose count in batch is maximum, or among the ? maximums defined by        <obj_n>."""        objects_idx = tf.where(self.gt_sem[0] > 0)  # (P, 2) \ WARNING: ALWAYS CONSIDER B=2 and 1st DIM. HAS OBJECTS        objects = tf.gather_nd(self.gt_obj_ids, objects_idx)  # get object ids        # get unique object ids and counts        object_id, _, count = tf.unique_with_counts(tf.reshape(objects, (-1,)), out_idx=tf.dtypes.int32)        # collect objects whose ratios are above a given threshold and learn from them (bbox)        original_obj_counts = tf.gather(self.placeholders['obj_ids_counts'], object_id)        ratios = tf.reshape(count, (-1,)) / tf.cast(tf.reshape(original_obj_counts, (-1,)), tf.int32)        best_idx = tf.where(tf.math.greater_equal(ratios, config.OBJ_RATIO))  # (?,1)        # if ratio not satisfied (best_idx is empty or 0), then take index of best ratio        # otherwise, keep object ids whose ratio is satisfied        # tf.cond(cond, true_fn, false_fn)        obj_id = tf.cond(tf.equal(tf.size(best_idx), 0),                         lambda: tf.reshape([object_id[tf.argmax(ratios)]], (-1,)),                         lambda: tf.gather(tf.reshape(object_id, (-1,)), best_idx))        batch_obj_ids = tf.reshape(self.gt_obj_ids, (-1,))        # where batch_obj_ids == obj_id with best ratio?        mask_per_obj = tf.equal(batch_obj_ids, tf.reshape(tf.random.shuffle(obj_id)[:obj_n], (-1, 1)))  # (2,4096)        mask = tf.reduce_sum(tf.cast(mask_per_obj, tf.int32),                             axis=0)  # flatten the mask as 1 vectors of 1s and 0s (4096,)        # return tf.reshape(obj_idx[:, 0], (-1, 1))        return tf.where(tf.not_equal(mask, 0)), tf.where(tf.equal(mask, 0)), mask_per_obj    def soft_argmax_metrics(self):        """Get metrics using soft-argmax, because differentiable"""        softmax = tf.nn.softmax(self.segmentation, axis=1)        pos = tf.cast(tf.range(2), tf.float32)        pred_sem = tf.reduce_sum(softmax * pos, axis=1)        # Differentiable metrics        y_true = tf.cast(self.gt_sem, tf.float32)        TP = tf.reduce_sum(pred_sem * y_true, axis=0)        FP = tf.reduce_sum(pred_sem * (1 - y_true), axis=0)        FN = tf.reduce_sum((1 - pred_sem) * y_true, axis=0)        return TP, FP, FN, pred_sem    def soft_argmax_metrics2(self):        """Get metrics using soft-argmax, because differentiable"""        softmax = tf.nn.softmax(self.segmentation * 6, axis=1)        gt_sem_enc = tf.one_hot(self.gt_sem, depth=2)        y_true = tf.cast(gt_sem_enc, tf.float32)        TP = tf.reduce_sum(tf.reduce_sum(softmax * y_true, axis=1), axis=0)        FP = tf.reduce_sum(tf.reduce_sum(softmax * (1 - y_true), axis=1), axis=0)        FN = tf.reduce_sum(tf.reduce_sum((1 - softmax) * y_true, axis=1), axis=0)        return TP, FP, FN    def tversky_loss(self, alph=0.1, smh=1):        TP, FN, FP = self.soft_argmax_metrics2()        index = (TP + smh) / (TP + (alph * FN) + ((1 - alph) * FP) + smh)        return 1 - index    def focal_tversky_loss(self, gamma=0.75):        return tf.pow(self.tversky_loss(), gamma)    def dice_loss(self, eps=1e-8):        _, _, _, pred_sem = self.soft_argmax_metrics()        y_true = tf.cast(self.gt_sem, tf.float32)        num = 2 * tf.reduce_sum(pred_sem * y_true, axis=0)        denom = tf.reduce_sum(pred_sem + y_true, axis=0)        return 1 - ((num + eps) / (denom + eps))    def penalty_loss(self, coef=0.5):        loss = self.dice_loss()        return loss / (1 + (coef * (1 - loss)))    def cross_entropy_focal(self, gamma=5):        # normal cross entropy if gamma = 0        y_true = tf.cast(tf.one_hot(self.gt_sem, depth=2), tf.float32)        y_pred = tf.nn.softmax(self.segmentation, axis=1)        ce = y_true * tf.math.log(y_pred) + (1 - y_true) * tf.math.log(1 - y_pred)        ce = ce * tf.pow(1 - y_pred, gamma)        ce = tf.reduce_sum(ce, axis=-1, keepdims=False)        return - tf.reduce_mean(ce, axis=0, keepdims=False)    def define_losses(self):        self.loss_weights = tf.constant(config.LOSS_WEIGHTS)        # Semantic loss        self.loss_sem = self.weighted_binary_crossentropy(            y_true=tf.cast(self.gt_sem, 'float32'),            y_pred=tf.nn.softmax(self.segmentation, axis=-1),            w0=config.SEG_WEIGHT_0s,            w1=config.SEG_WEIGHT_1s,            gamma=0)        # Get indices of positive semantics (seeds on objects).        positives_idx, negatives_idx, mask_per_obj = self.select_object_of_interest_from_batch(            obj_n=config.NUMB_OBJ_TO_LEARN)        # Size loss.        gt_batch_sizes = tf.gather_nd(self.placeholders['box_sizes'], self.gt_obj_ids)  # (N, 3) i.e., l,w,h        positive_sizes = tf.gather_nd(gt_batch_sizes, positives_idx)  # (pos, 3)        start, end = 2 + (config.ANGLE_BINS * 2), 2 + (config.ANGLE_BINS * 2) + 3        out_sizes = self.proposals[..., start:end]  # (P, 3)        self.pred_sizes = tf.gather_nd(out_sizes, positives_idx)  # (pos, 3)        self.loss_sizes = tf.reduce_mean(tf.reduce_sum(            tf.compat.v1.losses.huber_loss(                labels=positive_sizes,                predictions=self.pred_sizes,                reduction=tf.losses.Reduction.NONE), axis=-1)) * self.loss_weights[4]        # Center loss.        gt_batch_centers = tf.gather_nd(self.placeholders['centers'], self.gt_obj_ids)  # (N, 3)        self.positive_centers = tf.cast(tf.gather_nd(gt_batch_centers, positives_idx), tf.float32)  # (pos, 3)        self.positive_xyz = tf.gather_nd(self.pointset_norm_xyz[0], positives_idx)  # (pos, 3)        self.delta_gt = self.positive_centers - tf.gather_nd(self.pointset_xyz[0], positives_idx)        self.delta_pred = tf.gather_nd(self.pred_delta, positives_idx)        self.pred_centers = tf.gather_nd(self.pred_centers_xyz, positives_idx)  # (pos, 3)        self.loss_center = tf.reduce_mean(tf.reduce_sum(            tf.compat.v1.losses.huber_loss(                labels=self.delta_gt,                predictions=self.delta_pred,                reduction=tf.losses.Reduction.NONE), axis=-1)) * self.loss_weights[1]        # Centroid loss where we force the voted centers to aggregate        # closer to each other (xyz centers are collected per object        # in scene).        tmp = tf.cast(tf.transpose(tf.gather_nd(tf.transpose(mask_per_obj), positives_idx)), tf.float32)  # (2, 640)        centers_per_obj = tf.math.multiply(tf.expand_dims(tmp, -1), tf.expand_dims(self.pred_centers, 0))  # (2, 620, 3)        # Calculate the mean centers xyz per object.        nonzero_mask = tf.math.reduce_any(tf.not_equal(centers_per_obj, 0.0), axis=-1,                                          keepdims=True)  # (2, 620, 1) bool        n = tf.reduce_sum(tf.cast(nonzero_mask, 'float32'), axis=1, keepdims=True)  # (2, 1, 1)        centers_mean = tf.reduce_sum(centers_per_obj, axis=1, keepdims=True) / n  # (2, 1, 3)        # Calculate distance between these mean xyz and the centers        # voted per object.        tiled_mean = tf.tile(centers_mean, multiples=[1, tf.shape(tmp)[-1], 1])  # (2, 640, 3)        nonzero_float = tf.cast(nonzero_mask, tf.float32)  # (2, 640, 1)        nonzero_mean = tf.math.multiply(nonzero_float, tiled_mean)  # (2, 640, 3)        distances = tf.math.sqrt(            tf.reduce_sum(tf.math.square(centers_per_obj - nonzero_mean), axis=-1, keepdims=False))  # (2, 640)        self.loss_mean_centroid = tf.math.reduce_sum(tf.math.reduce_mean(distances, axis=1), axis=0) * 0.1        # Heading class loss.        gt_batch_angle_cls = tf.gather_nd(self.placeholders['box_angles_cls'], self.gt_obj_ids)  # (N, )        positive_angle_cls = tf.gather_nd(gt_batch_angle_cls, positives_idx)  # (pos, )        positive_angle_cls_enc = tf.one_hot(positive_angle_cls, depth=config.ANGLE_BINS)  # (pos, NH)        start, end = 2, 2 + config.ANGLE_BINS        out_angles_cls = self.proposals[..., start:end]  # (P, NH)        pred_angle_cls_enc = tf.gather_nd(out_angles_cls, positives_idx)  # (pos, NH) - binary one-hot        loss_angle_cls = tf.nn.softmax_cross_entropy_with_logits(            logits=pred_angle_cls_enc,            labels=positive_angle_cls_enc)        self.loss_angle_cls = tf.reduce_mean(loss_angle_cls) * self.loss_weights[2]        # Heading residual loss.        one_hot_targets = tf.gather_nd(tf.eye(config.ANGLE_BINS),                                       tf.expand_dims(self.placeholders['box_angles_cls'], 1))  # (N, NH)        one_hot_res = tf.cast(tf.expand_dims(self.placeholders['box_angles_res'], 1), tf.float32) * one_hot_targets        positive_angle_res = tf.gather_nd(one_hot_res, positives_idx)  # (pos, )        start, end = 2 + config.ANGLE_BINS, 2 + (config.ANGLE_BINS * 2)        out_angles_res = self.proposals[..., start:end]  # (pos, NH)        self.pred_angle_res_enc = tf.gather_nd(out_angles_res, positives_idx)  # (pos, NH)        self.loss_angle_res = tf.reduce_mean(tf.reduce_sum(            tf.compat.v1.losses.huber_loss(                labels=positive_angle_res,                predictions=self.pred_angle_res_enc,                reduction=tf.losses.Reduction.NONE), axis=-1)) * self.loss_weights[3]        # Box corners (regularization).        gt_batch_corners = tf.gather_nd(self.placeholders['box_vertices'], self.gt_obj_ids)  # (N, 8, 3)        self.positive_box_corners = tf.cast(tf.gather_nd(gt_batch_corners, positives_idx), tf.float32)  # (pos, 8, 3)        # Get angle class number take angle residual per row        # given class number (indices).        self.pred_angle_cls = tf.argmax(tf.nn.softmax(pred_angle_cls_enc, axis=-1), axis=-1)  # (pos, )        self.pred_angle_res = get_element(self.pred_angle_res_enc, self.pred_angle_cls)  # (pos, )        self.pred_box_corners = get_3D_box_corners(            box_size=self.pred_sizes,            angle_cls=tf.cast(self.pred_angle_cls, tf.float32),            angle_res=self.pred_angle_res,            center=self.pred_centers)        # Calculate euclidean distance between corners <xyz>,        # then take the mean and sum of distance per box (8 corners).        loss_corners = tf.stop_gradient(tf.reduce_sum(tf.reduce_mean(            tf.norm(self.positive_box_corners - self.pred_box_corners, ord='euclidean', axis=2), axis=1)))        self.loss_corners = loss_corners * self.loss_weights[5]        # Total loss        self.loss = (self.loss_sem + self.loss_center + self.loss_angle_cls +                     self.loss_angle_res + self.loss_sizes + self.loss_mean_centroid)    def get_progress(self, metrics):        """Returns progression message for defined metrics."""        val = ['{:.4f}'.format(v) for v in metrics]        nm = [[n, v] for n, v in zip(self.metric_names, val)]        return [" --- {0}: {1}".format(*lst) for lst in nm]    def generate_batch(self, training_phase, folder=None):        """Randomize data set selection from pointset folders. Then, generate batch        from a randomly selected folder. This allows to work on different 3D meshes        (from different pointset) during training when generating batches from those        meshes.        Args:            training_phase (str): Define 'training' state, or another state.            folder (str) training folder (pointset) of interest.        """        if (training_phase == 'training') and (config.FOLDERS_TO_USE is not None) and (                (not config.FOLDERS_TO_USE) is False):            msg = "\n✖ All provided folders <FOLDERS_TO_USE> must be usable folders with pre-processed data."            assert all(fld in self.sampler.folders[training_phase] for fld in config.FOLDERS_TO_USE) is True, msg            self.current_folder = folder if (folder is not None) else np.random.choice(config.FOLDERS_TO_USE)            self.sampler(training_phase, self.current_folder)  # load processed data from randomly chosen data folder        else:            rand = np.random.choice(self.sampler.folders[training_phase])            self.current_folder = folder if (folder is not None) else rand            self.sampler(training_phase, self.current_folder)  # load processed data from randomly chosen data folder        # Apply augmentation if 'training'.        augment = config.AUGMENT if training_phase == 'training' else False  # augment only when training        if (training_phase in ['to_detect', 'detect']) is False:            return self.sampler.generate_batch(augment=augment)        else:            return self.sampler.generate_batch_by_sliding_window()    @tf.function    def write_summary(self, step):        """Writes summary scalar to tensorboard."""        for tensor, name in zip(self.metrics, self.metric_names):            tf.summary.scalar(name, tensor, step=step)        tf.summary.scalar('sem_accuracy', self.sem_acc, step=step)    def train(self, sess_config, save_model=False, model_to_restore=None):        # Define learning rate variable.        lr = tf.Variable(config.LR, trainable=False)        self.change_lr = tf.compat.v1.assign(lr, self.placeholders['learning_rate'])        # Define optimizer.        optimizer = tf.compat.v1.train.AdamOptimizer(lr)        train_op = optimizer.minimize(self.loss)        # Summary merger.        self.merged = tf.compat.v1.summary.merge_all()        with tf.compat.v1.Session(config=sess_config) as sess:            # Write summary protocol buffers to event files.            try:                # Delete previous event file.                existing_summary_files_train = os.walk(self.train_summary_dir).__next__()[-1]                existing_summary_files_valid = os.walk(self.val_summary_dir).__next__()[-1]                if existing_summary_files_train:                    for file in existing_summary_files_train:                        os.remove(os.path.join(self.train_summary_dir, file))                if existing_summary_files_valid:                    for file in existing_summary_files_valid:                        os.remove(os.path.join(self.val_summary_dir, file))            except PermissionError:                pass            self.train_writer = tf.compat.v1.summary.FileWriter(logdir=self.train_summary_dir, graph=sess.graph)            self.validation_writer = tf.compat.v1.summary.FileWriter(logdir=self.val_summary_dir, graph=sess.graph)            # Initialize variables.            sess.run(tf.compat.v1.global_variables_initializer())            sess.run(tf.compat.v1.local_variables_initializer())            # Get checkpoint folder (create it if not existing).            if not os.path.exists(config.CHECKPOINT_DIR + config.MODEL_DIR):                os.mkdir(config.CHECKPOINT_DIR + config.MODEL_DIR)            # (optional) Restore model.            if model_to_restore:                self.saver.restore(sess, os.path.join(config.CHECKPOINT_DIR, model_to_restore))            else:                # or create new saving files otherwise                _ = open(os.path.join(config.CHECKPOINT_DIR + config.MODEL_DIR, 'training.txt'), 'w')                _ = open(os.path.join(config.CHECKPOINT_DIR + config.MODEL_DIR, 'validation.txt'), 'w')            # Get training folders.            training_poinset_folders = self.sampler.training_folders            print('\n∎ Training')            train_metrics, global_step = 0., 0            for epoch in range(config.MAX_ITER + 1):                # Change learning rate given epoch.                if (epoch % config.LR_CHANGE_EPOCH == 0) and (epoch != 0):                    value = sess.run(lr) / config.LR_CHANGE_VAL                    if value >= config.LR_MINIMUM:                        sess.run(self.change_lr, feed_dict={self.placeholders['learning_rate']: value})                # Sequentially learn through training folders.                random.shuffle(training_poinset_folders)                for step in range(len(training_poinset_folders)):                    # Generate batch (with randomization).                    batch_keys, batch = self.generate_batch(                        training_phase='training',                        folder=training_poinset_folders[step])                    batch_xyz = np.take(self.sampler.vertices_aug, batch_keys, axis=0)                    batch_sem = np.greater(self.sampler.obj_ids[batch_keys], 0).astype(np.int32)                    # Optimize.                    feed_dict = {self.placeholders['point_set']: batch,                                 self.placeholders['batch_xyz']: batch_xyz,                                 self.placeholders['batch_keys']: np.expand_dims(batch_keys, -1),                                 self.placeholders['training']: config.IS_TRAINING,                                 self.placeholders['object_ids']: self.sampler.obj_ids,                                 self.placeholders['box_sizes']: self.sampler.box_sizes,                                 self.placeholders['obj_ids_counts']: self.sampler.obj_ids_counts,                                 self.placeholders['centers']: self.sampler.centers_form,                                 self.placeholders['box_angles_cls']: self.sampler.box_angles_cls,                                 self.placeholders['box_angles_res']: self.sampler.box_angles_res,                                 self.placeholders['box_vertices']: self.sampler.box_vertices}                    sess.run(train_op, feed_dict=feed_dict)                    # Calculate metrics only for positives.                    if 1 in batch_sem:                        # Get metrics.                        metrics = np.array([sess.run(m, feed_dict=feed_dict) for m in self.metrics])                        # Estimate accuracy for semantics.                        sem_ratio = sess.run(self.sem_gt_ratio, feed_dict=feed_dict)                        # Calculate and display metrics after every number of                        # steps reached.                        train_metrics += metrics / config.SUMMARY_ITER                        if global_step % config.SUMMARY_ITER == 0:                            # Display results.                            text = self.get_progress(train_metrics)                            text = 'Epoch {} '.format(epoch) + 'folder: {}'.format(self.current_folder) \                                   + ''.join(text) + " --- {0}: {1:.5f}".format('sem_ratio', sem_ratio)                            print(text)                            # Write results.                            # Note: append 'a' is more stable than write 'w' while training.                            tmp = os.path.join(config.CHECKPOINT_DIR + config.MODEL_DIR, 'training.txt')                            with open(tmp, 'a') as file:                                file.write(text + "\n")                            # Write summaries.                            summary = sess.run(self.merged, feed_dict=feed_dict)                            self.train_writer.add_summary(summary, global_step=global_step)                            # Reset metrics.                            train_metrics = 0.                    if (global_step % config.VALIDATION_ITER == 0) and (global_step != 0):                        # Validation.                        tmp_keys, tmp_batch = self.generate_batch(training_phase='validation')                        tmp_xyz = np.take(self.sampler.vertices_aug, tmp_keys, axis=0)                        feed_dict = {self.placeholders['point_set']: tmp_batch,                                     self.placeholders['batch_xyz']: tmp_xyz,                                     self.placeholders['batch_keys']: np.expand_dims(tmp_keys, -1),                                     self.placeholders['training']: False,                                     self.placeholders['object_ids']: self.sampler.obj_ids,                                     self.placeholders['box_sizes']: self.sampler.box_sizes,                                     self.placeholders['obj_ids_counts']: self.sampler.obj_ids_counts,                                     self.placeholders['centers']: self.sampler.centers_form,                                     self.placeholders['box_angles_cls']: self.sampler.box_angles_cls,                                     self.placeholders['box_angles_res']: self.sampler.box_angles_res,                                     self.placeholders['box_vertices']: self.sampler.box_vertices}                        # Get metrics.                        metrics = np.array([sess.run(m, feed_dict=feed_dict) for m in self.metrics])                        # Write summaries.                        summary = sess.run(self.merged, feed_dict=feed_dict)                        self.validation_writer.add_summary(summary, global_step=global_step)                        # Display results.                        text = self.get_progress(metrics)                        text = 'Validation ' + 'folder: {}'.format(self.current_folder) + ''.join(text)                        print(text + '\n')                        # Write results.                        tmp = os.path.join(config.CHECKPOINT_DIR + config.MODEL_DIR, 'validation.txt')                        with open(tmp, 'a') as file:                            file.write(text + "\n")                    # ---                    global_step += 1                # ---                # Save model.                if (save_model is True) and (epoch % config.SAVE_ITER == 0):                    tmp = os.path.join(config.CHECKPOINT_DIR + config.MODEL_DIR, config.MODEL_NAME)                    self.saver.save(sess, tmp, global_step=epoch)    def test(self, model, sess_config):        print('\n∎ Testing with model {}'.format(model))        with tf.compat.v1.Session(config=sess_config) as sess:            # Initialize variables and restore model.            sess.run(tf.compat.v1.global_variables_initializer())            sess.run(tf.compat.v1.local_variables_initializer())            self.saver.restore(sess, os.path.join('./checkpoint/', model))            print('\n○ {} restored.\n'.format(model))            n_folder = len(self.sampler.folders['test'])            tot_metrics, tot_prec, tot_rec, obj_n = 0., 0., 0., 0.            for folder in self.sampler.folders['test']:                # Get pointset batch.                batch_keys, batch = self.generate_batch(training_phase='test', folder=folder)                batch_xyz = self.sampler.vertices_aug[batch_keys]                # Calculate metrics.                feed_dict = {self.placeholders['point_set']: batch,                             self.placeholders['batch_xyz']: batch_xyz,                             self.placeholders['batch_keys']: np.expand_dims(batch_keys, -1),                             self.placeholders['training']: False,                             self.placeholders['object_ids']: self.sampler.obj_ids,                             self.placeholders['box_sizes']: self.sampler.box_sizes,                             self.placeholders['obj_ids_counts']: self.sampler.obj_ids_counts,                             self.placeholders['centers']: self.sampler.centers_form,                             self.placeholders['box_angles_cls']: self.sampler.box_angles_cls,                             self.placeholders['box_angles_res']: self.sampler.box_angles_res,                             self.placeholders['box_vertices']: self.sampler.box_vertices}                metrics = np.array([sess.run(m, feed_dict=feed_dict) for m in self.metrics])                # ---                # Increment metrics.                obj_n += len(self.sampler.obj_voxel_centers_idx)                tot_metrics += metrics                # Calculate metrics per folder, average by the number of                # ground truth object in that folder.                obj = len(self.sampler.obj_voxel_centers_idx)                text = self.get_progress(metrics)                text = 'Folder {}: {} objects'.format(self.current_folder, obj) + ''.join(text)                print(text)            # Total average metrics.            print('\nTotal objects: ', obj_n)            text = self.get_progress(tot_metrics / n_folder)  # normalize because iou is averaged per batch (folder)            text = 'Total average: ' + ''.join(text)            print(text)    @staticmethod    def non_maximum_suppression(boxes, scores, dist_mat, iou_thresh=0.5):        """Apply NMS.        See details: https://towardsdatascience.com/non-maximum-suppression-nms-93ce178e177c"""        # Copy boxes and scores.        _boxes = copy.deepcopy(boxes)        _scores = copy.deepcopy(scores)        boxes_idxs_to_return = []        tmp_indices = list(np.arange(len(_scores)))  # fixed indices or 'fidx' (do not change in loop)        while len(tmp_indices) != 0:            # Collect indices given minimum distance between points.            dist = np.sum(dist_mat[np.asarray(tmp_indices)], axis=1)            idx = np.argmin(dist)            idxm = tmp_indices[idx]  # get fidx given local index            bm = np.expand_dims(_boxes[idxm], axis=0)  # get box given indices            boxes_idxs_to_return.append(idxm)  # keep current box            # Redefine list of indices without fidx of current box.            tmp_indices = [i for i in tmp_indices if i != idxm]            idx_to_remove = []            for j in tmp_indices:                # Calculate iou between current box (bm) and boxes for                # remaining indices.                bj = np.expand_dims(_boxes[j], axis=0)                iou = get_mean_iou_3d(bm, bj)                if iou > iou_thresh:                    idx_to_remove.append(j)            # Redefine fixed indices.            tmp_indices = [i for i in tmp_indices if i not in idx_to_remove]        # At this stage, we may need to select one of the box        # indices, e.g. the one whose box has        # (1) the highest volume        '''boxes = _boxes[np.array(boxes_idxs_to_return)]        volumes = get_boxes_volumes(boxes)        best = np.argmax(volumes)'''        # (2) the best score        '''scores = _scores[np.array(boxes_idxs_to_return)]'''        # (3) or the closest to others        tmp = np.sum(dist_mat, axis=1)[np.array(boxes_idxs_to_return)]        best = np.argmin(tmp)        return np.array(boxes_idxs_to_return[best])  # return indices as array    def show_ground_truth(self, folder):        """Display ground truth elements in scene."""        # Get pointset batch.        batch_keys, batch = self.generate_batch('to_detect', folder)        # Define object vertices vector.        shp = self.sampler.vertices_aug.shape[0]        vertices_sem = np.zeros(shape=(shp,), dtype='int32')        # Get object IDs.        obj_ids = reload_data(os.path.join('to_detect', folder), ['object_ids'])[0]        # Make object IDs ranging from 0...n count (instead of using the source        # numbering) because objects from current folder have e.g. numbers 45,        # 48, 65 from GIS, but we need ids in increasing order, with increment of        # 1, starting from 0 (0 being the background).        gis_obj_ids = np.asarray(obj_ids).astype(np.int32)  # gis numbering        obj_ids = copy.deepcopy(gis_obj_ids)        sorted_ = np.sort(np.unique(gis_obj_ids))  # sort gis numbering        for i, id_ in enumerate(sorted_):            mask = obj_ids == id_            obj_ids[mask] = i        # Get 3D boxes given 2D boxes determined via OpenCV.        centers_xy, box_params, box_vertices = get_boxes_2D(            vertices=self.sampler.vertices_aug,            object_ids=obj_ids,            kernel=2,            display=False)        centers_form, box_vertices, _, _, _ = get_boxes_3D(            centers_xy=centers_xy,            box_vertices=box_vertices,            object_ids=obj_ids,            vertices=self.sampler.vertices_aug,            box_params=box_params)        # Display semantics.        indicator = np.greater(obj_ids, 0).astype(np.int32)        pos_keys = np.where(indicator > 0)[0]        pos_keys = np.array([i for i in pos_keys if i in batch_keys])        vertices_sem[pos_keys] = 1        # Build array of colors to display per cloud point.        print('\t▹ plotting')        func = lambda x: '#000000' if x < 1 else '#d99748'        colors = [func(i) for i in vertices_sem]        plot_point_cloud(self.sampler.vertices_form, boxes=box_vertices, semantics=colors)    def detect(self, model, sess_config, folder, cluster_radius, NMS, iou_thresh,               overlap_ratio, semantics_only=False):        """Detect boxes from model."""        with tf.compat.v1.Session(config=sess_config) as sess:            # Initialize variables and restore model.            print('\n∎ Detection with {}'.format(model))            sess.run(tf.compat.v1.global_variables_initializer())            sess.run(tf.compat.v1.local_variables_initializer())            self.saver.restore(sess, os.path.join('./checkpoint/', model))            print('\t▹ {} restored.'.format(model))            # (1) Get positive semantics in dataset via patching steps.            print('\t▹ processing {}'.format(folder))            batch_maker = self.generate_batch('to_detect', folder)            # Define object vertices vector.            shp = self.sampler.vertices_form.shape[0]            vertices_sem = np.zeros(shape=(shp,), dtype='int32')            cnt = 0            dataset_pos_keys, dataset_boxes, dataset_centers, dataset_scores, dataset_xyz = [], [], [], [], []            for batch_keys, batch in batch_maker:                # Get pointset vertices.                batch_xyz = self.sampler.vertices_aug[batch_keys]                print('\t\tbatch {} done'.format(cnt))                cnt += 1                # Make semantic predictions.                feed_dict = {self.placeholders['point_set']: batch,                             self.placeholders['batch_xyz']: batch_xyz,                             self.placeholders['batch_keys']: np.expand_dims(batch_keys, -1),                             self.placeholders['training']: False}                pred_sem = sess.run(self.pred_sem, feed_dict=feed_dict)                # Get dataset keys for which semantics are positives.                if 1 in pred_sem:                    # Get indices of positive segmentation within batch.                    # WARNING: Run it to get fixed indices.                    batch_pos_indices = np.where(pred_sem > 0)[0]                    dataset_xyz += [batch_xyz[batch_pos_indices]]                    pos_keys = np.reshape(batch_keys[batch_pos_indices], (-1,))                    dataset_pos_keys += list(pos_keys)                    # --- DISPLAY BOXES                    if not semantics_only:                        batch_pos_indices = np.reshape(batch_pos_indices, (-1, 1))                        start, end = 2, 2 + config.ANGLE_BINS                        out = self.proposals[..., start:end]                        angle_cls = tf.argmax(tf.nn.softmax(out, axis=-1), axis=-1)                        angle_cls = tf.gather_nd(angle_cls, batch_pos_indices)                        start, end = 2 + config.ANGLE_BINS, 2 + (config.ANGLE_BINS * 2)                        angle_res = self.proposals[..., start:end]                        angle_res = tf.gather_nd(angle_res, batch_pos_indices)                        start, end = 2 + (config.ANGLE_BINS * 2), 2 + (config.ANGLE_BINS * 2) + 3                        sizes = self.proposals[..., start:end]                        sizes = tf.gather_nd(sizes, batch_pos_indices)                        pred_angle_res = get_element(angle_res, angle_cls)                        obj_centers = tf.gather_nd(self.pred_centers_xyz, batch_pos_indices)                        corners = get_3D_box_corners(sizes, tf.cast(angle_cls, tf.float32), pred_angle_res, obj_centers)                        # Predict boxes and scores.                        obj_boxes = sess.run(corners, feed_dict=feed_dict)                        obj_scores = sess.run(tf.gather_nd(                            tf.reduce_max(tf.nn.softmax(self.segmentation, axis=1), axis=1), batch_pos_indices),                            feed_dict=feed_dict)                        dataset_boxes += [obj_boxes]                        dataset_centers += [sess.run(obj_centers, feed_dict=feed_dict)]                        dataset_scores += [obj_scores]            # Convert as array and rule out same keys.            unique_pos_keys, unique_pos_idxs = np.unique(np.array(dataset_pos_keys), return_index=True)            if not list(unique_pos_keys):                # no objects found                print('No objects found in dataset.')                return            if semantics_only:                # (A) DISPLAY SEMANTICS                vertices_sem[unique_pos_keys] = 1                # Build array of colors to display per cloud point.                print('\t▹ plotting')                func = lambda x: '#000000' if x < 1 else '#d99748'                colors = [func(i) for i in vertices_sem]                plot_point_cloud(self.sampler.vertices_form, semantics=colors)            else:                # (B) FIND CLUSTERS                dataset_boxes = np.reshape(np.array(dataset_boxes), (-1, 8, 3))[unique_pos_idxs]                dataset_centers = np.reshape(np.array(dataset_centers), (-1, 3))[unique_pos_idxs]                dataset_scores = np.reshape(np.array(dataset_scores), (-1,))[unique_pos_idxs]                obj_surface = np.reshape(np.array(dataset_xyz), (-1, 3))[unique_pos_idxs]                # Calculate distance matrix between object points and cluster                # closest points (within ball radius) given that their center                # fall within the given radius.                dist_matrix = squared_dist_np(dataset_centers, dataset_centers)                mask = np.less_equal(dist_matrix, cluster_radius).astype(np.int32)                obj_indices, to_skip = [], []                for row in mask:                    if 1 in row:                        indices = np.where(row > 0)[0]                        if any(i in to_skip for i in indices):                            # It is possible that 2 close objects have their ball                            # region intersecting, hence we check if this intersection                            # does not reach a given threshold (otherwise we rule out                            # one).                            ratios = []                            for inds in obj_indices:                                intersect = list(set(indices) & set(inds))                                ratios += [len(intersect) / len(inds)]  # overlap ratio                            if any(i > overlap_ratio for i in ratios):                                # Skip current row if related object overlaps too much                                # with known objects.                                continue                        to_skip += list(indices)                        obj_indices.append(indices)  # all objects collected from a cluster                print('\t▹ number of boxes:', len(obj_indices))                # --- FIND BEST BOX(ES) FROM CLUSTER(S)                # Apply NMS per cluster.                best_boxes, best_centers, cluster_centers = [], [], []                for cluster_idxs in obj_indices:                    # Collect boxes/scores of objects whose semantic is 1 in current cluster.                    tmp_boxes = dataset_boxes[cluster_idxs]                    tmp_scores = dataset_scores[cluster_idxs]                    tmp_centers = dataset_centers[cluster_idxs]                    if NMS:                        # Get the best box for current cluster using NMS.                        dist_matrix = squared_dist_np(tmp_centers, tmp_centers)                        nms_i = self.non_maximum_suppression(                            tmp_boxes, tmp_scores, dist_matrix,                            iou_thresh=iou_thresh)                    else:                        # Get the box whose volume aggregate most of the vertices                        # segmented as 1.                        counts = []                        for bbox in tmp_boxes:                            # Take bounding box limits.                            bbox_min, bbox_max = bbox.min(axis=0), bbox.max(axis=0)                            cnt = 0                            for i, xyz in enumerate(obj_surface):                                if (all(xyz <= bbox_max) is True) and (all(xyz >= bbox_min) is True):                                    cnt += 1                            counts.append(cnt)                        nms_i = np.argmax(counts)                    # Collect box and center of current cluster.                    best_box = tmp_boxes[nms_i]                    best_cent = tmp_centers[nms_i]                    # Assign color to vertices within box predicted.                    _min, _max = best_box.min(axis=0), best_box.max(axis=0)                    for i, xyz in enumerate(self.sampler.vertices_form):                        if (all(xyz <= _max) is True) and (all(xyz >= _min) is True):                            vertices_sem[i] = 1                    # ---                    best_boxes += [best_box]                    best_centers += [best_cent]                    cluster_centers += [tmp_centers]                # Build array of colors to display per cloud point.                print('\t▹ plotting')                func = lambda x: '#000000' if x < 1 else '#d99748'                colors = [func(i) for i in vertices_sem]                plot_point_cloud(self.sampler.vertices_form,                                 boxes=best_boxes,                                 pred_centers=np.vstack(cluster_centers),                                 semantics=colors)